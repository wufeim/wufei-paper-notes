
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Compositional Convolutional Neural Networks: A Deep Architecture with Innate Robustness to Partial Occlusion &#8212; Wufei Ma 1.0.0 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Amodal Segmentation through Out-of-Task and Out-of-Distribution with a Bayesian Model" href="amodal_seg_bayesian_model.html" />
    <link rel="prev" title="Compositional Models" href="index.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Wufei Ma</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../by_areas.html">
  By Areas
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../aug_2022.html">
  Aug 2022
 </a>
</li>

    
    <li class="nav-item">
        <a class="nav-link nav-external" href="https://wufeim.github.io">About me<i class="fas fa-external-link-alt"></i></a>
    </li>
    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  By Areas
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../transformers/index.html">
   Transformers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../transformers/rethinking_positional_encoding_in_language_pretraining.html">
     Rethinking Positional Encoding in Language Pre-training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../transformers/paper1.html">
     Paper 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../transformers/paper2.html">
     Paper 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nerf/index.html">
   NeRF
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../nerf/pixelnerf.html">
     pixelNeRF: Neural Radiance Fields from One or Few Images
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Compositional Models
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Compositional Convolutional Neural Networks: A Deep Architecture with Innate Robustness to Partial Occlusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="amodal_seg_bayesian_model.html">
     Amodal Segmentation through Out-of-Task and Out-of-Distribution with a Bayesian Model
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-ideas">
   Key Ideas
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#technical-details">
   Technical Details
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notes">
   Notes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="compositional-convolutional-neural-networks-a-deep-architecture-with-innate-robustness-to-partial-occlusion">
<h1>Compositional Convolutional Neural Networks: A Deep Architecture with Innate Robustness to Partial Occlusion<a class="headerlink" href="#compositional-convolutional-neural-networks-a-deep-architecture-with-innate-robustness-to-partial-occlusion" title="Permalink to this headline">#</a></h1>
<ul class="simple">
<li><p>Authors: Adam Kortylewski, Ju He, Qing Liu, Alan Yuille</p></li>
<li><p>Affiliations: Johns Hopkins University</p></li>
<li><p>CVPR, 2020</p></li>
<li><p>Links: <a class="reference external" href="https://arxiv.org/abs/2003.04490">arXiv</a>, <a class="reference external" href="https://openaccess.thecvf.com/content_CVPR_2020/html/Kortylewski_Compositional_Convolutional_Neural_Networks_A_Deep_Architecture_With_Innate_Robustness_CVPR_2020_paper.html">thecvf.com</a></p></li>
</ul>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<p>Recent findings show that deep convolutional neural networks (DCNNs) do not generalize well under partial occlusion. The authors propose to integrate compositional models and DCNNs into a unified deep model with innate robustness to partial occlusion, termed <strong>Compositional CNN</strong>.</p>
<p>Results show that DCNNs do not classify occluded objects robustly, even when trained with data that is strongly augmented with partial occlusions. The proposed model, CompositionalNets, outperforms standard DNNs by a wide margin at classifying partially occluded objects, even when it has not been exposed to occluded objects during training.</p>
</section>
<section id="key-ideas">
<h2>Key Ideas<a class="headerlink" href="#key-ideas" title="Permalink to this headline">#</a></h2>
<p><strong>Fully generative compositional models.</strong> Let <span class="math notranslate nohighlight">\(F^l \in \mathbb{R}^{H \times W \times D}\)</span> be the output of a layer <span class="math notranslate nohighlight">\(l\)</span> in a DCNN. The authors proposed a differentiable generative compositional model of the feature activations <span class="math notranslate nohighlight">\(p(F \mid y)\)</span> for an object class <span class="math notranslate nohighlight">\(y\)</span>, which is modeled as a mixture of von-Mises-Fisher (vMF) distributions:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
p(F \mid \theta_y) &amp; = \prod_p p(f_p \mid \mathcal{A}_{p, y}, \Lambda) \\
p(f_p \mid \mathcal{A}_{p, y}, \Lambda) &amp; = \sum_k \alpha_{p, k, y}p(f_p \mid \lambda_k)
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_k = \{ \mathcal{A}_y, \Lambda\}\)</span> are the model parameters and <span class="math notranslate nohighlight">\(\mathcal{A}_y = \{\mathcal{A}_{p, y}\}\)</span> are the parameters of the mixture models at every position <span class="math notranslate nohighlight">\(p \in \mathcal{P}\)</span> on the 2D lattice. In particular, <span class="math notranslate nohighlight">\(\mathcal{A}_{p, y} = \{\alpha_{p,0,y}, \dots, \alpha_{p, K, y} \mid \sum_{k=0}^K \alpha_{p, k, y} = 1\}\)</span> are the mixture coefficients and <span class="math notranslate nohighlight">\(\Lambda = \{\lambda_k = \{\sigma_k, \mu_k\} \mid k = 1, \dots, K\}\)</span> are the parameters of the vMF distribution:</p>
<div class="math notranslate nohighlight">
\[p(f_p \mid \lambda_k) = \frac{e^{\sigma_k \mu_k^\top f_p}}{Z(\sigma_k)}, \lVert f_p \rVert = 1, \lVert \mu_k \rVert = 1\]</div>
<p>where <span class="math notranslate nohighlight">\(Z(\sigma_k)\)</span> is the normalization constant.</p>
<p><strong>Occlusion reasoning.</strong> Compositional models can be augmented with an occlusion model at each position <span class="math notranslate nohighlight">\(p\)</span>, either the object model <span class="math notranslate nohighlight">\(p(f_p \mid \mathcal{A}_{p, y}^m, \Lambda)\)</span> or the occluder model <span class="math notranslate nohighlight">\(p(f_p \mid \beta, \Lambda)\)</span> is active:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
p(F \mid \theta_y^m, \beta) &amp; = \prod_p p(f_p, z_p^m = 0)^{1-z_p^m} p(f_p, z_p^m 1)^{z_p^m} \\
p(f_p, z_p^m = 1) &amp; = p(f_p \mid \beta, \Lambda) p(z_p^m = 1) \\
p(f_p, z_p^m = 0) &amp; = p(f_p \mid \mathcal{A}_{p, y}^m, \Lambda) p(z_p^m = 0)
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{Z}^m = \{z_p^m \in \{0, 1\} \mid p \in \mathcal{P}\}\)</span>.</p>
<figure class="align-default" id="id2">
<a class="reference internal image-reference" href="../_images/compositional_cnn-1.png"><img alt="../_images/compositional_cnn-1.png" src="../_images/compositional_cnn-1.png" style="height: 220px;" /></a>
<figcaption>
<p><span class="caption-text">Figure 1: Feed-forward inference with a CompositionalNet.</span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="technical-details">
<h2>Technical Details<a class="headerlink" href="#technical-details" title="Permalink to this headline">#</a></h2>
<p><strong>Inference as feed-forward neural network.</strong> The computational graph of the fully generative compositional model is directed and acyclic, and can be inferenced with a single forward pass.</p>
<p><strong>End-to-end training of CompositionalNets.</strong> The model is fully differentiable and can be trained end-to-end using backpropagation. The loss function is composed of four terms</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(y, y', F, T) = \mathcal{L}_\text{class}(y, y') + \gamma_1 \mathcal{L}_\text{weight}(\omega) + \gamma_2 \mathcal{L}_\text{vwf}(F, \Lambda) + \gamma_3 \mathcal{L}_\text{mix}(F, \mathcal{A}_y)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{L}_\text{class}\)</span> is the cross-entropy loss between the network output <span class="math notranslate nohighlight">\(y'\)</span> and the true class label <span class="math notranslate nohighlight">\(y\)</span>, <span class="math notranslate nohighlight">\(\mathcal{L}_\text{weight}\)</span> is the weight regularization on the DCNN parameters, <span class="math notranslate nohighlight">\(\mathcal{L}_\text{vmf}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{L}_\text{mix}\)</span> regularize the parameters of the compositional model to have maximum likelihood for the features in <span class="math notranslate nohighlight">\(F\)</span>.</p>
<p><strong>Classification results for vehicles of PASCAL3D+ with different levels of artificial occlusion.</strong></p>
<figure class="align-default" id="id3">
<a class="reference internal image-reference" href="../_images/compositional_cnn-2.png"><img alt="../_images/compositional_cnn-2.png" src="../_images/compositional_cnn-2.png" style="height: 200px;" /></a>
<figcaption>
<p><span class="caption-text">Figure 2: Classification results for vehicles of PASCAL3D+ with different levels of artificial occlusion.</span><a class="headerlink" href="#id3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Classification results for vehicles of MS-COCO with different levels of real occlusion.</strong></p>
<figure class="align-default" id="id4">
<a class="reference internal image-reference" href="../_images/compositional_cnn-3.png"><img alt="../_images/compositional_cnn-3.png" src="../_images/compositional_cnn-3.png" style="height: 180px;" /></a>
<figcaption>
<p><span class="caption-text">Figure 3: Classification results for vehicles of MS-COCO with different levels of real occlusion.</span><a class="headerlink" href="#id4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Occlusion localization results.</strong></p>
<figure class="align-default" id="id5">
<a class="reference internal image-reference" href="../_images/compositional_cnn-4.png"><img alt="../_images/compositional_cnn-4.png" src="../_images/compositional_cnn-4.png" style="height: 280px;" /></a>
<figcaption>
<p><span class="caption-text">Figure 4: Occlusion localization results.</span><a class="headerlink" href="#id5" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">#</a></h2>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<p>[1] A. Kortylewski, J. He, Q. Liu, A. Yuille. <a class="reference external" href="https://arxiv.org/abs/2003.04490">“Compositional convolutional neural networks: A deep architecture with innate robustness to partial occlusion.”</a>. In <em>CVPR</em>, 2020.</p>
</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="index.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Compositional Models</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="amodal_seg_bayesian_model.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Amodal Segmentation through Out-of-Task and Out-of-Distribution with a Bayesian Model</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2022, Wufei Ma.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.2.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>