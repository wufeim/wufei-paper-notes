Search.setIndex({docnames:["aug_2022","by_areas","index","transformers/index","transformers/paper1","transformers/paper2","transformers/rethinking_positional_encoding_in_language_pretraining"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,sphinx:56},filenames:["aug_2022.rst","by_areas.rst","index.rst","transformers/index.rst","transformers/paper1.rst","transformers/paper2.rst","transformers/rethinking_positional_encoding_in_language_pretraining.rst"],objects:{},objnames:{},objtypes:{},terms:{"1":3,"2":3,"2022":2,"class":[4,5,6],By:2,The:[4,5,6],add:[4,5,6],affili:[4,5,6],area:2,attent:[4,5,6],aug:2,author:[4,5,6],bert:[4,5,6],between:[4,5,6],bias:[4,5,6],bring:[4,5,6],cl:[4,5,6],correl:[4,5,6],di:[4,5,6],dot:[4,5,6],e:[4,5,6],embed:[4,5,6],encod:[0,2,3,4,5],g:[4,5,6],guolin:[4,5,6],he:[4,5,6],heterogen:[4,5,6],idea:[],includ:[4,5,6],inform:[4,5,6],involv:[4,5,6],ke:[4,5,6],kei:[],label_by_area:[],languag:[0,2,3],liu:[4,5,6],microsoft:[4,5,6],mix:[4,5,6],nearbi:[4,5,6],paper:[],posit:[0,2,3,4,5],pre:[0,2,3],product:[4,5,6],research:[4,5,6],resourc:[4,5,6],rethink:[0,2,3],sort:[],term:[4,5,6],tie:[4,5,6],token:[4,5,6],toward:[4,5,6],train:[0,2,3],transform:[1,2,4,5,6],two:[4,5,6],unwant:[4,5,6],usual:[4,5,6],vision:[],we:[4,5,6],which:[4,5,6],word:[4,5,6],yan:[4,5,6]},titles:["Aug 2022","By Areas","Paper Reading Notes","Transformers","Paper 1","Paper 2","Rethinking Positional Encoding in Language Pre-training"],titleterms:{"1":4,"2":5,"2022":0,By:1,area:1,aug:0,content:2,encod:6,idea:[4,5,6],kei:[4,5,6],languag:6,note:2,paper:[2,3,4,5],posit:6,pre:6,read:2,rethink:6,train:6,transform:3,vision:[]}})