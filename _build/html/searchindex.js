Search.setIndex({docnames:["aug_2022","by_areas","compositional/amodal_seg_bayesian_model","compositional/compositional_cnn","compositional/index","index","nerf/index","nerf/pixelnerf","transformers/index","transformers/paper1","transformers/paper2","transformers/rethinking_positional_encoding_in_language_pretraining"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,sphinx:56},filenames:["aug_2022.rst","by_areas.rst","compositional/amodal_seg_bayesian_model.rst","compositional/compositional_cnn.rst","compositional/index.rst","index.rst","nerf/index.rst","nerf/pixelnerf.rst","transformers/index.rst","transformers/paper1.rst","transformers/paper2.rst","transformers/rethinking_positional_encoding_in_language_pretraining.rst"],objects:{},objnames:{},objtypes:{},terms:{"0":[2,3],"1":[2,3,7,8,11],"110m":11,"15595":[],"2":[3,7,8,11],"2006":[],"2019":11,"2020":3,"2021":[2,7,11],"2022":[2,5],"2d":[2,3,7],"3":[3,7,11],"3d":7,"4":[3,11],"5":11,"6":11,"class":[2,3,9,10,11],"do":[3,11],"final":[2,7],"function":3,"new":11,"return":7,"true":3,A:[0,2,4,5,7,11],By:5,For:7,In:[2,3,7,11],It:11,One:[0,5,6],The:[2,3,7,9,10,11],Then:7,To:7,_:3,_y:3,a_:[],ab:11,ablat:11,absolut:11,acl:11,across:11,activ:3,acycl:3,ad:[7,11],adam:[2,3],add:[9,10,11],addit:[2,11],affili:[2,3,7,9,10,11],aggreg:7,agnost:7,aim:2,alan:[2,3],alex:7,align:[3,7],all:11,allow:7,alpha_:[3,11],also:2,altern:2,amod:[0,4,5],an:[2,3,7,11],analysi:11,angjoo:7,annot:2,appli:2,approach:[2,7],ar:[2,3,7,11],arbitrari:7,architectur:[0,4,5,11],area:5,argu:11,art:7,artifici:3,arxiv:[3,11],associ:7,attent:[9,10,11],aug:5,augment:3,author:[2,3,7,9,10,11],averag:7,b_a:2,background:2,backpropag:3,bar:2,baselin:7,bayesian:[0,4,5],been:3,begin:[3,7],below:[7,11],benchmark:11,berkelei:7,bert:[9,10,11],beta:3,between:[3,9,10,11],bewteen:11,bia:11,bias:[9,10,11],bilinear:7,block:7,both:7,bound:2,boundari:2,box:2,bring:[9,10,11],c:[7,11],calcul:11,calibr:7,call:11,camera:7,can:[3,7],captur:7,categori:[2,7],cl:[9,10,11],clark:11,classif:3,classifi:3,cnn:3,coco:3,coeffici:3,color:7,com:3,complex:11,compos:3,composit:[0,1,5],compositionalnet:3,comput:[3,7],concentr:11,condit:[2,7],consid:11,constant:3,continu:7,convolut:[0,4,5],correl:[9,10,11],cross:3,current:7,cvpr:[2,3,7],d:[2,3,7,11],data:[2,3],dataset:7,dcnn:3,deep:[0,4,5],demonstr:11,densiti:7,depend:11,depict:7,detail:[],dev:11,develop:11,di:[9,10,11],differ:3,differenti:[3,7],direct:[3,7],distribut:[0,3,4,5,11],dnn:3,doe:11,dot:[3,7,9,10,11],ds:7,dt:7,dtu:7,dure:3,e:[3,7,9,10,11],each:[3,7,11],effect:11,effici:11,either:3,embed:[9,10,11],encod:[0,5,7,8,9,10],end:[3,7],entropi:3,eta:2,even:[2,3],everi:[3,7],exactli:11,exist:7,exp:7,experi:[7,11],experiment:11,explain:11,explan:11,expos:3,extend:7,extract:7,f:[2,3,7],f_1:7,f_2:7,f_a:2,f_p:3,featur:[2,3,7,11],feed:3,few:[0,5,6],field:[0,5,6],figur:[3,7,11],find:3,fine:11,first:11,fisher:[2,3],fix:11,focu:11,follow:11,foreground:2,formul:2,forward:3,four:[3,11],frac:[3,11],framework:7,from:[0,2,5,6,11],fulli:3,fuse:11,g:[9,10,11],gamma:7,gamma_1:3,gamma_2:3,gamma_3:3,gener:[2,3],give:2,given:[2,7],global:7,glue:11,gong19a:[],gong:11,graph:3,guolin:[9,10,11],h:3,ha:3,handl:7,hat:7,have:[3,11],he:[3,9,10,11],head:11,henc:2,heterogen:[9,10,11],hopkin:[2,3],howev:11,html:[],http:[],i:[2,7,11],iclr:11,icml:11,idea:[],ij:11,illustr:11,imag:[0,2,5,6],implement:11,includ:[9,10,11],incorpor:7,increas:11,independ:7,indic:2,infer:3,inferenc:3,inform:[7,9,10,11],initi:7,innat:[0,4,5],input:[2,7],instead:11,int_:7,integr:3,intermedi:7,interpol:7,introduc:2,invis:2,invol:7,involv:[9,10,11],its:7,j:3,john:[2,3],ju:3,just:11,k:[3,11],kanazawa:7,ke:[9,10,11],kei:[],khandelw:11,kortylewski:[2,3],l:[3,11],label:[2,3],label_by_area:[],labmda:[],lambda:3,lambda_k:3,languag:[0,5,8],larg:2,latent:2,lattic:3,layer:[3,7,11],learn:[2,7,11],learnabl:11,learnt:2,left:7,let:[2,3,7],level:3,levi:11,li:11,like:11,likelihood:3,link:[2,3,7,11],liu:[3,9,10,11],local:[3,7,11],look:11,loss:3,lvert:3,m:[2,3,7],mai:11,make:11,man:11,mani:[7,11],map:2,margin:[2,3],mathbb:[3,7,11],mathbf:7,mathcal:[2,3],matric:11,matthew:7,maximum:3,method:[2,11],microsoft:[9,10,11],mid:[2,3],mise:[2,3],mix:[3,9,10,11],mixtur:[2,3],mlr:[],model:[0,1,3,5,7],moreov:11,ms:3,mu_k:3,multipl:7,n:7,nearbi:[9,10,11],necessarili:11,nerf:[1,5,7],network:[0,2,4,5,7],neural:[0,2,4,5,6],non:2,normal:3,note:[],novel:7,number:7,o:11,object:[2,3],obtain:7,occlud:[2,3],occlus:[0,2,4,5,7],often:11,omega:3,one:7,onli:[2,11],onto:7,oper:7,optim:7,org:[],other:11,out:[0,4,5],outperfom:2,outperform:[2,3,7],output:3,overrightarrow:2,overview:7,p:[2,3,7],p_a:2,p_i:11,p_iw:11,p_j:11,p_jw:11,paper:11,paramet:[3,11],partial:[0,4,5],particular:3,pascal3d:3,pass:[3,7],phi:7,pi:7,pipelin:7,pixelnerf:[0,5,6],plane:7,point:7,pool:7,posit:[0,3,5,8,9,10],pre:[0,5,8],predict:7,press:[],prior:2,problem:2,proceed:[],prod_:2,prod_p:3,product:[9,10,11],progresss:11,project:[2,7,11],propos:[2,3,7,11],psi:2,pyramid:7,q:[3,11],qin:11,qing:3,quantit:7,r:[3,7,11],radianc:[0,5,6],rai:7,real:[3,11],reason:3,recent:3,reconstruct:7,redund:11,regular:[3,11],rel:11,relat:11,remov:11,render:7,represent:7,requir:7,research:[9,10,11],residu:7,resnet:7,resourc:[9,10,11],result:[3,7,11],rethink:[0,5,8],retriev:7,rgb:7,right:7,robust:[0,4,5],robustli:3,rvert:3,s:[7,11],same:[2,11],scene:7,score:11,second:11,seem:11,segment:[0,4,5],self:11,sentenc:11,set:11,sever:11,shape:2,shapenet:7,share:11,show:[3,7,11],sigma:7,sigma_k:3,significantli:7,singl:[3,7],some:11,sort:[],space:7,spatial:2,sqrt:11,stack:11,stand:11,standard:[3,7],state:7,strong:11,strongli:3,studi:11,subsequ:11,sum_:[2,3],sum_k:3,sun:2,supervis:2,synthesi:7,t:[3,7,11],t_f:7,t_n:7,tak:2,tancik:7,task:[0,4,5],technic:[],term:[3,9,10,11],test:7,text:[3,11],textual:11,thecvf:3,therefor:11,theta:11,theta_i:3,theta_k:3,thi:[2,7,11],third:11,through:[0,4,5],thte:7,tie:[9,10,11],time:[2,3,7],token:[9,10,11],top:[3,11],toward:[9,10,11],train:[0,2,3,5,8],transform:[1,5,7,9,10,11],treat:11,tupe:11,two:[9,10,11],u:11,uc:7,under:3,unifi:3,uniform:11,univers:[2,3],unti:11,unwant:[9,10,11],us:[2,3],usual:[9,10,11],v97:[],v:7,valu:11,variabl:2,variant:11,vector:[7,11],vehicl:3,veri:11,via:7,vicki:7,view:7,vision:[],visual:11,vmf:3,volum:7,volumetr:7,von:[2,3],vwf:3,w:[2,3,7,11],w_a:2,w_i:11,w_iw:11,w_j:11,w_jw:11,wang:11,we:[7,9,10,11],weight:[2,3],well:3,what:11,when:[2,3],where:[2,3,7],which:[2,3,9,10,11],whole:11,wide:[2,3],within:2,without:2,word:[9,10,11],work:[7,11],world:7,x:7,y:[2,3],yan:[9,10,11],ye:7,yihong:2,yu:7,yuill:[2,3],z:[3,11],z_p:3,zeta:2},titles:["Aug 2022","By Areas","Amodal Segmentation through Out-of-Task and Out-of-Distribution with a Bayesian Model","Compositional Convolutional Neural Networks: A Deep Architecture with Innate Robustness to Partial Occlusion","Compositional Models","Paper Reading Notes","NeRF","pixelNeRF: Neural Radiance Fields from One or Few Images","Transformers","Paper 1","Paper 2","Rethinking Positional Encoding in Language Pre-training"],titleterms:{"1":9,"2":10,"2022":0,A:3,By:1,One:7,amod:2,architectur:3,area:1,aug:0,bayesian:2,composit:[3,4],content:5,convolut:3,deep:3,detail:[2,3,7,11],distribut:2,encod:11,few:7,field:7,from:7,idea:[2,3,7,9,10,11],imag:7,innat:3,kei:[2,3,7,9,10,11],languag:11,model:[2,4],nerf:6,network:3,neural:[3,7],note:[2,3,5,7,11],occlus:3,out:2,paper:[4,5,6,8,9,10],partial:3,pixelnerf:7,posit:11,pre:11,radianc:7,read:5,refer:[2,3,7,11],rethink:11,robust:3,segment:2,summari:[2,3,7,11],task:2,technic:[2,3,7,11],through:2,train:11,transform:8,vision:[]}})